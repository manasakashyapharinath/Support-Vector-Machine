{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SUPPORT VECTOR MACHINE\n",
    "SVM are the supervised learning algorithms used for the classification and regression analysis. Suppose a set of training samples are given which are classified into two or more categories. SVM builds a model based on this training dataset and classifies the new test samples into these categories. How well the SVM would classify the test sample can be measured using performance measure. There are two types of classification that can be performed by SVM : Linear and Non - Linear (which uses kernel trick and mapps the inputs into high dimensional feature space)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cross_validation import KFold\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.cross_validation import cross_val_score\n",
    "import numpy as np\n",
    "import scipy.io as sio\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn import cross_validation \n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.cross_validation import KFold\n",
    "import pylab as pl\n",
    "import pandas as pd\n",
    "from csv import reader\n",
    "import csv\n",
    "from sklearn import metrics\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from matplotlib.colors import ListedColormap\n",
    "from numpy import random\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn import datasets, svm\n",
    "from numpy import where\n",
    "\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dataset information: Iris dataset from the sklearn library is used. There are totally 150 instances. In the orignal Dataset, there are 4 predictor variables, but for the ease of implementation, we have considered only the first two predictors(X) which are \n",
    "1. sepal length in cm \n",
    "2. sepal width in cm \n",
    "Y is the response varibale representing the class of the plant. We consider only two classes - Setosa (0) and Versicolour(1)\n",
    "\n",
    "After loading the dataset, spliting of the dataset into train split and test split is performed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris = datasets.load_iris()\n",
    "X = iris.data[:, :2]\n",
    "y = iris.target\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implementation of the Linear Kernel : \n",
    "\n",
    "Linear Kernel is given by, K = x * x' -> dot product of two vectors\n",
    "\n",
    "Lambda: is a scalar hyper parameter. \n",
    "\n",
    "We use existing SVM library and define the kernel as 'Linear'. Using the GridSearchCV API function, 5 fold cross-validation is performed for each different value of 'C'. The best parameters are noted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "THis is Linear Kernel\n",
      "('Best score for data:', 0.81904761904761902)\n",
      "('Best alpha:', 0.1)\n",
      "('Best Kernel:', 'linear')\n",
      "RMean squared error: 0.45\n"
     ]
    }
   ],
   "source": [
    "kr1 = GridSearchCV(svm.SVC(kernel='linear'), cv=5,\n",
    "                  param_grid={\"C\": [1e0, 0.1, 1e-2, 1e-3, 0.5, 2,3,5]})\n",
    "kr1.fit(X_train, y_train)\n",
    "y_kr1 = kr1.predict(X_test)\n",
    "print(\"THis is Linear Kernel\")\n",
    "print('Best score for data:', kr1.best_score_) \n",
    "print('Best alpha:',kr1.best_estimator_.C) \n",
    "print('Best Kernel:',kr1.best_estimator_.kernel)\n",
    "print(\"RMean squared error: %.2f\" % np.sqrt(np.mean((y_kr1 - y_test) ** 2)))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implementation of the Polynomial Kernel:\n",
    "\n",
    "Polynomial Kernel is given by, K = (gamma ( x x') + R)^M\n",
    "\n",
    "Gamma: This is the scalar hyper parameter\n",
    "R : This is hyperparameter vector matrix whose shape is same as that of the gram matrix.\n",
    "Lambda: is a scalar hyper parameter. \n",
    "M : Degree of the gram matrix.\n",
    "\n",
    "We use existing SVM library and define the kernel as 'Poly'. Using the GridSearchCV API function, 5 fold cross-validation is performed for each different value of 'lambda', 'gamma', 'R' and 'degree'. The best parameters are noted.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is Polynomial Kernel\n",
      "('Best score for data:', 0.83809523809523812)\n",
      "('Best alpha:', 0.1)\n",
      "('Best Kernel:', 'poly')\n",
      "('Best Gamma:', 2)\n",
      "('Best degree:', 1)\n",
      "('Best coefficient:', 1)\n",
      "RMean squared error: 0.45\n"
     ]
    }
   ],
   "source": [
    "kr2 = GridSearchCV(svm.SVC(kernel='poly'), cv=5,\n",
    "                  param_grid={\"C\": [1e0, 0.1, 1e-2, 1e-3, 0.5, 2,3,5],\n",
    "                              \"gamma\": [0.001,0.0001,0.01,0.1,1,0.5,2,3],\n",
    "                              \"degree\":[1,2,3],\n",
    "                              \"coef0\":[1,2,3]})\n",
    "kr2.fit(X_train, y_train)\n",
    "y_kr2 = kr2.predict(X_test)\n",
    "print(\"This is Polynomial Kernel\")\n",
    "print('Best score for data:', kr2.best_score_) \n",
    "print('Best alpha:',kr2.best_estimator_.C) \n",
    "print('Best Kernel:',kr2.best_estimator_.kernel)\n",
    "print('Best Gamma:',kr2.best_estimator_.gamma)\n",
    "print('Best degree:',kr2.best_estimator_.degree)\n",
    "print('Best coefficient:',kr2.best_estimator_.coef0)\n",
    "print(\"RMean squared error: %.2f\" % np.sqrt(np.mean((y_kr2 - y_test) ** 2)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implementation of the Gaussian Kernel :\n",
    "\n",
    "Gaussian Kernel is given by, K(x,x') = exp( gamma * (-sum(x-x')))\n",
    "\n",
    "Gamma: This is the scalar hyper parameter\n",
    "Lambda: is a scalar hyper parameter.\n",
    "\n",
    "We use existing SVM library and define the kernel as 'rbf'. Using the GridSearchCV API function, 5 fold cross-validation is performed for each different value of 'lambda' and 'gamma'. The best parameters are noted.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "THis is Gaussian Kernel\n",
      "('Best score for data:', 0.82857142857142863)\n",
      "('Best alpha:', 1.0)\n",
      "('Best Kernel:', 'rbf')\n",
      "('Best Gamma:', 0.1)\n",
      "RMean squared error: 0.45\n"
     ]
    }
   ],
   "source": [
    "kr3 = GridSearchCV(svm.SVC(kernel='rbf'), cv=5,\n",
    "                  param_grid={\"C\": [1e0, 0.1, 1e-2, 1e-3, 0.5, 2,3,5],\n",
    "                              \"gamma\": [0.001,0.0001,0.01,0.1,1,0.5,2,3]})\n",
    "kr3.fit(X_train, y_train)\n",
    "y_kr3 = kr3.predict(X_test)\n",
    "print(\"THis is Gaussian Kernel\")\n",
    "print('Best score for data:', kr3.best_score_) \n",
    "print('Best alpha:',kr3.best_estimator_.C) \n",
    "print('Best Kernel:',kr3.best_estimator_.kernel)\n",
    "print('Best Gamma:',kr3.best_estimator_.gamma)\n",
    "print(\"RMean squared error: %.2f\" % np.sqrt(np.mean((y_kr3 - y_test) ** 2)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comparing the Performance Measure of each kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Best score using Linear Kernel:', 0.81904761904761902)\n",
      "('Best score using Polynomial Kernel:', 0.83809523809523812)\n",
      "('Best score using Gaussian Kernel:', 0.82857142857142863)\n"
     ]
    }
   ],
   "source": [
    "print('Best score using Linear Kernel:', kr1.best_score_)\n",
    "print('Best score using Polynomial Kernel:', kr2.best_score_)\n",
    "print('Best score using Gaussian Kernel:', kr3.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
